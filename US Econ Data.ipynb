{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from full_fred.fred import Fred\n",
    "import yfinance as yf\n",
    "from scipy import stats\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer, Image\n",
    "from reportlab.lib import colors\n",
    "from reportlab.lib.styles import getSampleStyleSheet\n",
    "from reportlab.lib.units import inch\n",
    "from io import BytesIO\n",
    "from reportlab.lib.styles import ParagraphStyle\n",
    "import glob\n",
    "import jinja2\n",
    "import pdfkit\n",
    "import datetime\n",
    "from scipy.stats import norm\n",
    "from datetime import datetime\n",
    "\n",
    "#import nasdaqdatalink\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FRED Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fred = Fred('key.txt')\n",
    "fred.set_api_key_file('key.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YF.download() has changed argument auto_adjust default to True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>6.440331</td>\n",
       "      <td>6.455077</td>\n",
       "      <td>6.391278</td>\n",
       "      <td>6.422877</td>\n",
       "      <td>493729600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>6.451467</td>\n",
       "      <td>6.487880</td>\n",
       "      <td>6.417460</td>\n",
       "      <td>6.458087</td>\n",
       "      <td>601904800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>6.348847</td>\n",
       "      <td>6.477046</td>\n",
       "      <td>6.342226</td>\n",
       "      <td>6.451466</td>\n",
       "      <td>552160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>6.337109</td>\n",
       "      <td>6.379843</td>\n",
       "      <td>6.291066</td>\n",
       "      <td>6.372319</td>\n",
       "      <td>477131200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>6.379242</td>\n",
       "      <td>6.379845</td>\n",
       "      <td>6.291370</td>\n",
       "      <td>6.328685</td>\n",
       "      <td>447610800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>68.823036</td>\n",
       "      <td>68.973147</td>\n",
       "      <td>68.496201</td>\n",
       "      <td>68.924723</td>\n",
       "      <td>48478800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>70.188507</td>\n",
       "      <td>70.205456</td>\n",
       "      <td>68.927145</td>\n",
       "      <td>68.956196</td>\n",
       "      <td>93121200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>70.161850</td>\n",
       "      <td>71.171429</td>\n",
       "      <td>69.755116</td>\n",
       "      <td>70.481430</td>\n",
       "      <td>146266000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>70.578293</td>\n",
       "      <td>70.861558</td>\n",
       "      <td>69.053038</td>\n",
       "      <td>70.079558</td>\n",
       "      <td>144114400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>71.093964</td>\n",
       "      <td>71.101226</td>\n",
       "      <td>70.094071</td>\n",
       "      <td>70.193335</td>\n",
       "      <td>100805600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2516 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Price           Close       High        Low       Open     Volume\n",
       "Ticker           AAPL       AAPL       AAPL       AAPL       AAPL\n",
       "Date                                                             \n",
       "2010-01-04   6.440331   6.455077   6.391278   6.422877  493729600\n",
       "2010-01-05   6.451467   6.487880   6.417460   6.458087  601904800\n",
       "2010-01-06   6.348847   6.477046   6.342226   6.451466  552160000\n",
       "2010-01-07   6.337109   6.379843   6.291066   6.372319  477131200\n",
       "2010-01-08   6.379242   6.379845   6.291370   6.328685  447610800\n",
       "...               ...        ...        ...        ...        ...\n",
       "2019-12-24  68.823036  68.973147  68.496201  68.924723   48478800\n",
       "2019-12-26  70.188507  70.205456  68.927145  68.956196   93121200\n",
       "2019-12-27  70.161850  71.171429  69.755116  70.481430  146266000\n",
       "2019-12-30  70.578293  70.861558  69.053038  70.079558  144114400\n",
       "2019-12-31  71.093964  71.101226  70.094071  70.193335  100805600\n",
       "\n",
       "[2516 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yf.download('AAPL', start='2010-01-01', end='2020-01-01')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily(x):\n",
    "    dta = yf.download(tickers=x,period='max',interval = '1d')\n",
    "    dta[x] = dta['Close']\n",
    "    dta = dta.drop(columns=['Open','High','Low','Close','Volume'])\n",
    "    dta[x] = np.array(dta[x])\n",
    "    return dta[x]\n",
    "\n",
    "def meta_data(x):\n",
    "    y = fred.get_a_series(x)\n",
    "    dta = pd.DataFrame(y['seriess']).transpose()\n",
    "    return dta\n",
    "\n",
    "def data(x,y):\n",
    "    a = fred.get_series_df(x,frequency=y)\n",
    "    a.value = a.value.replace('.',np.nan)\n",
    "    a.value = a.value.ffill()\n",
    "    a.index = a.date\n",
    "    a = a.drop(columns=['date','realtime_start','realtime_end'])\n",
    "    a.value = a.value.astype('float')\n",
    "    return a\n",
    "\n",
    "def data2(x):\n",
    "    a = fred.get_series_df(x,frequency='d')\n",
    "    a.value = a.value.replace('.',np.nan)\n",
    "    a.value = a.value.ffill()\n",
    "    a.index = a.date\n",
    "    a = a.drop(columns=['date','realtime_start','realtime_end'])\n",
    "    a.value = a.value.astype('float')\n",
    "    return a\n",
    "\n",
    "def fed_annual(x):\n",
    "    a = fred.get_series_df(x,frequency='a')\n",
    "    a.value = a.value.replace('.',np.nan)\n",
    "    a.value = a.value.ffill()\n",
    "    a.index = pd.to_datetime(a.date)\n",
    "    a = a.drop(columns=['date','realtime_start','realtime_end'])\n",
    "    a.value = a.value.astype('float')\n",
    "    return a\n",
    "\n",
    "def growth(x):\n",
    "    y = (x/x.shift(1))-1\n",
    "    y = y.fillna(0)\n",
    "    return y\n",
    "\n",
    "def exp(x):\n",
    "    p = x\n",
    "    p = round(p,2)\n",
    "    bins , counts = np.unique(p,return_counts=True)\n",
    "    a = pd.DataFrame()\n",
    "    a['bins'] =bins\n",
    "    a['counts'] = counts/sum(counts)\n",
    "    e = sum(a.bins * a.counts)\n",
    "    e = [e]\n",
    "    return a\n",
    "\n",
    "def nasdaq(x):\n",
    "    df = nasdaqdatalink.get(x)\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    return df\n",
    "\n",
    "def options_data(Ticker, nth_expiration_date):\n",
    "    \"\"\"\n",
    "    Retrieves option chain data for a given ticker and expiration date.\n",
    "    \n",
    "    Parameters:\n",
    "    - Ticker (str): Ticker symbol of the stock.\n",
    "    - nth_expiration_date (int): Index of the expiration date in the list of available expiration dates.\n",
    "    \n",
    "    Returns:\n",
    "    - ticker: Ticker object.\n",
    "    - ticker_option_chain: Option chain data for the specified expiration date.\n",
    "    - current_price: Current price of the underlying asset.\n",
    "    \"\"\"\n",
    "    current_price = daily(Ticker).tail(1)\n",
    "    ticker = yf.Ticker(Ticker)\n",
    "    ticker_option_chain = ticker.option_chain(ticker.options[nth_expiration_date])\n",
    "    return ticker, ticker_option_chain, current_price\n",
    "\n",
    "def plot_options(nth_expiration_date, strike_price):\n",
    "    \"\"\"\n",
    "    Plots option data including strike prices, last prices, and implied volatilities for calls and puts.\n",
    "    \n",
    "    Parameters:\n",
    "    - nth_expiration_date (int): Index of the expiration date in the list of available expiration dates.\n",
    "    - strike_price (float): Strike price for the options.\n",
    "    \"\"\"\n",
    "    fig, ax1 = plt.subplots(figsize=(20, 10))\n",
    "    exp_date = options_data(nth_expiration_date)[1]\n",
    "\n",
    "    plt.title(f\"Options Last Price - Expiration {exp_date}\")\n",
    "    ax1.plot(options_data(nth_expiration_date)[0].calls.strike, options_data(nth_expiration_date)[0].calls[p], 'ro')\n",
    "    ax1.axvline(x=options_data(nth_expiration_date)[2], color='k', linestyle='--', linewidth=1)\n",
    "    ax1.legend(['Calls', 'Current Price'], loc='upper left')\n",
    "    \n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(options_data(nth_expiration_date)[0].puts.strike, options_data(nth_expiration_date)[0].puts[p], 'o')\n",
    "    ax2.legend(['Puts'], loc='upper right')\n",
    "    \n",
    "    \n",
    "def black_scholes(ticker, K, expiration_date, r, option_type='call'):\n",
    "    \"\"\"\n",
    "    Calculate the price and Greeks of a European option using the Black-Scholes model.\n",
    "\n",
    "    Parameters:\n",
    "        ticker (str): Ticker symbol of the underlying stock\n",
    "        K (float): Strike price\n",
    "        expiration_date (str): Expiration date of the option in the format 'YYYY-MM-DD'\n",
    "        r (float): Risk-free interest rate (annualized, as a decimal)\n",
    "        option_type (str): Type of option, either 'call' or 'put' (default is 'call')\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the theoretical price and Greeks of the European option\n",
    "    \"\"\"\n",
    "    # Get latest stock price\n",
    "    S = daily(ticker).tail(1).values\n",
    "\n",
    "    # Calculate volatility (sigma)\n",
    "    sigma = daily(ticker).std()\n",
    "\n",
    "    # Calculate time until expiration\n",
    "    current_date = datetime.now()\n",
    "    expiration_date = datetime.strptime(expiration_date, '%Y-%m-%d')\n",
    "    T = (expiration_date - current_date).days / 365.0  # Time to expiration in years\n",
    "\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "\n",
    "    # Calculate option price\n",
    "    if option_type == 'call':\n",
    "        option_price = S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
    "    elif option_type == 'put':\n",
    "        option_price = K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid option_type. Must be either 'call' or 'put'.\")\n",
    "\n",
    "    # Calculate Greeks\n",
    "    delta = norm.cdf(d1) if option_type == 'call' else norm.cdf(d1) - 1\n",
    "    gamma = norm.pdf(d1) / (S * sigma * np.sqrt(T))\n",
    "    theta = (-S * norm.pdf(d1) * sigma / (2 * np.sqrt(T))\n",
    "             - r * K * np.exp(-r * T) * norm.cdf(d2) if option_type == 'call' else\n",
    "             -S * norm.pdf(d1) * sigma / (2 * np.sqrt(T))\n",
    "             + r * K * np.exp(-r * T) * norm.cdf(-d2))\n",
    "    vega = S * np.sqrt(T) * norm.pdf(d1)\n",
    "    rho = K * T * np.exp(-r * T) * norm.cdf(d2) if option_type == 'call' else -K * T * np.exp(-r * T) * norm.cdf(-d2)\n",
    "\n",
    "    return {\n",
    "        'option_price': option_price,\n",
    "        'delta': delta,\n",
    "        'gamma': gamma,\n",
    "        'theta': theta,\n",
    "        'vega': vega,\n",
    "        'rho': rho\n",
    "    }\n",
    "\n",
    "def binomial_option_price(ticker, K, expiration_date, r, n, option_type='call'):\n",
    "    \"\"\"\n",
    "    Calculate the price of an American option using the Binomial Options Pricing Model.\n",
    "\n",
    "    Parameters:\n",
    "        ticker (str): Ticker symbol of the underlying stock\n",
    "        K (float): Strike price\n",
    "        expiration_date (str): Expiration date of the option in the format 'YYYY-MM-DD'\n",
    "        r (float): Risk-free interest rate (annualized, as a decimal)\n",
    "        n (int): Number of time steps in the binomial tree\n",
    "        option_type (str): Type of option, either 'call' or 'put' (default is 'call')\n",
    "\n",
    "    Returns:\n",
    "        float: Theoretical price of the American option\n",
    "    \"\"\"\n",
    "    # Get latest stock price\n",
    "    S = daily(ticker).tail(1).values\n",
    "\n",
    "    # Calculate volatility (sigma)\n",
    "    sigma = daily(ticker).std()\n",
    "    \n",
    "    # Calculate time until expiration\n",
    "    current_date = datetime.now()\n",
    "    expiration_date = datetime.strptime(expiration_date, '%Y-%m-%d')\n",
    "    T = (expiration_date - current_date).days / 365.0  # Time to expiration in years\n",
    "\n",
    "    dt = T / n  # Time step\n",
    "    u = np.exp(sigma * np.sqrt(dt))  # Up factor\n",
    "    d = 1 / u  # Down factor\n",
    "    p = (np.exp(r * dt) - d) / (u - d)  # Probability of up move\n",
    "\n",
    "    # Initialize the option price tree\n",
    "    option_price_tree = np.zeros((n + 1, n + 1))\n",
    "    \n",
    "    # Calculate option prices at expiration\n",
    "    for j in range(n + 1):\n",
    "        if option_type == 'call':\n",
    "            option_price_tree[n, j] = max(0, S * (u ** j) * (d ** (n - j)) - K)\n",
    "        elif option_type == 'put':\n",
    "            option_price_tree[n, j] = max(0, K - S * (u ** j) * (d ** (n - j)))\n",
    "\n",
    "    # Calculate option prices at earlier nodes\n",
    "    for i in range(n - 1, -1, -1):\n",
    "        for j in range(i + 1):\n",
    "            if option_type == 'call':\n",
    "                option_price_tree[i, j] = max(0, np.exp(-r * dt) * (p * option_price_tree[i + 1, j] + (1 - p) * option_price_tree[i + 1, j + 1]))\n",
    "            elif option_type == 'put':\n",
    "                option_price_tree[i, j] = max(0, np.exp(-r * dt) * (p * option_price_tree[i + 1, j] + (1 - p) * option_price_tree[i + 1, j + 1]))\n",
    "\n",
    "    return option_price_tree[0, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fed Data id codes\n",
    "ids = ['gdp', 'm1v', 'm2v', 'GFDEBTN', 'RESPPANWW', 'QBPBSTAS',\n",
    "       'TOTALSL', 'DRALACBS', 'PAYEMS', 'unrate', 'CIVPART',\n",
    "       'CPIAUCSL','PCE','RSXFS','TOTALSA','JTSJOL','INDPRO','CSUSHPINSA'\n",
    "       ,'IEABC','BOPGSTB','ATLSBUSRGEP','TTLCONS','QBPQYNTIY','H8B1058NCBCMG','TMBACBW027SBOG'\n",
    "       ,'QBPBSTASSCUSTRSC','QBPQYNUMINST','WSHOMCB','DCPF3M','TOTBORR'\n",
    "       ,'BAMLHYH0A0HYM2TRIV','BUSINV','TOTBUSSMSA','FRGSHPUSM649NCIS'\n",
    "       ,'PETROLEUMD11','RHORUSQ156N','ACTLISCOUUS','HOSMEDUSM052N'\n",
    "       ,'PATENTUSALLTOTAL','MNFCTRIRSA','MNFCTRIMSA','DTCDISA066MSFRBNY','RETAILIMSA'\n",
    "       ,'RSCCAS','DFF','DCPF3M','DGS10','DGS1','DGS5','DGS30','DGS2','DGS1','DGS2'\n",
    "       ,'DGS20','DGS3','DGS7','DSPIC96','DRCCLACBS','PSAVERT','DTB4WK','DTB3','PPIACO','GDPC1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for i in ids:\n",
    "    y = fred.get_a_series(i)\n",
    "    x = y['seriess']\n",
    "    a = pd.DataFrame(x).transpose()\n",
    "    b = a[0]\n",
    "    df[b.id] = b\n",
    "\n",
    "df = df.transpose()\n",
    "df = df.drop(columns=['seasonal_adjustment','popularity','units','realtime_start','realtime_end'])\n",
    "df = df.sort_values(by='observation_start')\n",
    "df = df.reset_index()\n",
    "\n",
    "df = df.drop(columns='index')\n",
    "#df.to_excel('meta_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = list(df.id)\n",
    "names = list(df.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yoga\\AppData\\Local\\Temp\\ipykernel_8056\\961566858.py:33: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  a.value = a.value.replace('.',np.nan)\n"
     ]
    }
   ],
   "source": [
    "dta = pd.DataFrame()\n",
    "\n",
    "for i in ids:\n",
    "    y = fed_annual(i)\n",
    "    dta[i] = y.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FRED API Data Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labor Market\n",
    "labor_market = list(['PAYEMS','CIVPART','UNRATE','JTSJOL','ICSA','AWHAETP','CES0500000003','CE16OV','CLF16OV'])\n",
    "\n",
    "#Rates\n",
    "rates = list(['DTB4WK','DTB3','DGS1','DGS2','DGS3','DGS5','DGS7','DGS10','DGS20','DGS30','DFF','DCPF3M'])\n",
    "\n",
    "#Production\n",
    "production = list(['GDP','GDPC1','GDI','A261RX1Q020SBEA'])\n",
    "\n",
    "#Consumer Spending\n",
    "consumer_spending = list(['TOTALSA','RETAILIMSA','TOTBUSSMSA','BOPGSTB','RSCCAS','RSXFS','BUSINV','ATLSBUSRGEP','DSPIC96'])\n",
    "\n",
    "#Consumer Debt\n",
    "consumer_debt = list(['TOTALSL','GFDEBTN','H8B1058NCBCMG','RESPPANWW','TMBACBW027SBOG','DRALACBS'])\n",
    "\n",
    "#Housing\n",
    "housing = list(['RHORUSQ156N','CSUSHPINSA','TTLCONS','ACTLISCOUUS','EXHOSLUSM495S','HOSMEDUSM052N'])\n",
    "\n",
    "#Monetary & Prices\n",
    "prices = list(['CPIAUCSL','PCE','PPIACO'])\n",
    "money = list(['M2','M2V'])\n",
    "\n",
    "#Government Debt\n",
    "government_debt = list(['QBPBSTAS','QBPBSTASSCUSTRSC','WSHOMCB','GFDEBTN'])\n",
    "\n",
    "#Trade\n",
    "trade = list(['FRGSHPUSM649NCIS','BOPGSTB','PETROLEUMD11','DTCDISA066MSFRBNY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod = pd.DataFrame()\n",
    "\n",
    "for i in production:\n",
    "    y = data(i,'q')\n",
    "    prod[i] = y.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = pd.DataFrame()\n",
    "\n",
    "for i in labor_market:\n",
    "    y = data(i,'m')\n",
    "    lm[i] = y.value\n",
    "\n",
    "lm['labor_demand'] = (lm['CLF16OV'] + lm.JTSJOL)/1000\n",
    "lm['labor_supply'] = lm['CE16OV']/1000\n",
    "\n",
    "#Labor Market\n",
    "labor_market = lm\n",
    "#labor_market.index = pd.to_datetime(labor_market.index)\n",
    "\n",
    "labor_market['labor_difference'] = labor_market['labor_supply']-labor_market['labor_demand']\n",
    "labor_market['payems_change'] = labor_market['PAYEMS']-labor_market['PAYEMS'].shift(1)\n",
    "labor_market['awh_yoy'] = (labor_market['AWHAETP']/labor_market['AWHAETP'].shift(12)-1)*100\n",
    "labor_market['ahe_yoy'] = (labor_market['CES0500000003']/labor_market['CES0500000003'].shift(12)-1)*100\n",
    "labor_market.columns = [\"All Employees, Total Nonfarm\", \"Labor Force Participation Rate\", \"Unemployment Rate\", \"Job Openings: Total Nonfarm\",\"Initial Claims\", \"Average Weekly Hours\", \"Average Hourly Earnings\",\"Civilial Labor Force Level\",\"Employment Level\",\"Labor Demand\",\"Labor Supply\",\"Labor Difference\",\"Nonfarm Change\",\"AWH YoY%\",\"AHE YoY%\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pd.DataFrame()\n",
    "\n",
    "for i in rates:\n",
    "    y = data(i,'d')\n",
    "    r[i] = y.value\n",
    "#r.index = pd.to_datetime(r.index)\n",
    "\n",
    "\n",
    "#Treasury Yields table\n",
    "yields = r.drop(columns=['DFF','DCPF3M'])\n",
    "yields.columns = ['1mo','3mo','1yr','2yr','3yr','5yr','7yr','10yr','20yr','30yr']\n",
    "yield_curve = yields.loc[r.index.max()]\n",
    "#yields.index = yields.index.strftime('%Y-%m-%d')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#US Sectors\n",
    "#Tickers\n",
    "sectors = ['XLY','XLP','XLE','XLF','XLV','XLI','XLB','XLRE','XLK','XLC','XLU','^GSPC']\n",
    "sectors_names = ['Cons. Discreat.','Cons. Staples','Energy','Financials',\n",
    "                 'Health Care','Industrials','Materials','Real Estate','Tech',\n",
    "                 'Comms','Utilitites','S&P 500']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  12 of 12 completed\n"
     ]
    }
   ],
   "source": [
    "sectors_data = daily(sectors)\n",
    "#sectors_data.index = pd.to_datetime(sectors_data.index)\n",
    "#sectors_data = sectors_data.groupby(pd.Grouper(freq='1ME')).last()\n",
    "#sectors_data_growth = sectors_data.pct_change().fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 12\u001b[0m\n\u001b[0;32m      8\u001b[0m     corp_debt[i] \u001b[38;5;241m=\u001b[39m data(i,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m#corp_debt.index = pd.to_datetime(corp_debt.index)\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m corp_debt_y \u001b[38;5;241m=\u001b[39m \u001b[43mcorp_debt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGrouper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m1YE\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean()\n\u001b[0;32m     13\u001b[0m corp_debt_std \u001b[38;5;241m=\u001b[39m corp_debt\u001b[38;5;241m.\u001b[39mrolling(\u001b[38;5;241m21\u001b[39m)\u001b[38;5;241m.\u001b[39mstd()\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#Corporate Debt Yields\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yoga\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:9170\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[1;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   9167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m level \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   9168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 9170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9171\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9172\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9173\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9176\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yoga\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\groupby.py:1329\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[1;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[0;32m   1328\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1329\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1330\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1332\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1334\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mno_default\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1337\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m observed \u001b[38;5;129;01mis\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(ping\u001b[38;5;241m.\u001b[39m_passed_categorical \u001b[38;5;28;01mfor\u001b[39;00m ping \u001b[38;5;129;01min\u001b[39;00m grouper\u001b[38;5;241m.\u001b[39mgroupings):\n",
      "File \u001b[1;32mc:\\Users\\Yoga\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\groupby\\grouper.py:929\u001b[0m, in \u001b[0;36mget_grouper\u001b[1;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;66;03m# a passed-in Grouper, directly convert\u001b[39;00m\n\u001b[0;32m    928\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Grouper):\n\u001b[1;32m--> 929\u001b[0m     grouper, obj \u001b[38;5;241m=\u001b[39m \u001b[43mkey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_grouper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    931\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m grouper, \u001b[38;5;28mfrozenset\u001b[39m(), obj\n",
      "File \u001b[1;32mc:\\Users\\Yoga\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\resample.py:2282\u001b[0m, in \u001b[0;36mTimeGrouper._get_grouper\u001b[1;34m(self, obj, validate)\u001b[0m\n\u001b[0;32m   2278\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_grouper\u001b[39m(\n\u001b[0;32m   2279\u001b[0m     \u001b[38;5;28mself\u001b[39m, obj: NDFrameT, validate: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   2280\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[BinGrouper, NDFrameT]:\n\u001b[0;32m   2281\u001b[0m     \u001b[38;5;66;03m# create the resampler and return our binner\u001b[39;00m\n\u001b[1;32m-> 2282\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_resampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r\u001b[38;5;241m.\u001b[39m_grouper, cast(NDFrameT, r\u001b[38;5;241m.\u001b[39mobj)\n",
      "File \u001b[1;32mc:\\Users\\Yoga\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\resample.py:2272\u001b[0m, in \u001b[0;36mTimeGrouper._get_resampler\u001b[1;34m(self, obj, kind)\u001b[0m\n\u001b[0;32m   2263\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ax, TimedeltaIndex):\n\u001b[0;32m   2264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TimedeltaIndexResampler(\n\u001b[0;32m   2265\u001b[0m         obj,\n\u001b[0;32m   2266\u001b[0m         timegrouper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2269\u001b[0m         gpr_index\u001b[38;5;241m=\u001b[39max,\n\u001b[0;32m   2270\u001b[0m     )\n\u001b[1;32m-> 2272\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   2273\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly valid with DatetimeIndex, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2274\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimedeltaIndex or PeriodIndex, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2275\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got an instance of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(ax)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2276\u001b[0m )\n",
      "\u001b[1;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'Index'"
     ]
    }
   ],
   "source": [
    "#Corporate debt \n",
    "\n",
    "corp = list(['BAMLC1A0C13YEY','BAMLC2A0C35YEY','BAMLC3A0C57YEY','BAMLC4A0C710YEY','BAMLC7A0C1015YEY','BAMLC8A0C15PYEY','BAMLH0A0HYM2EY','BAMLC0A0CMEY'])\n",
    "\n",
    "corp_debt = pd.DataFrame()\n",
    "\n",
    "for i in corp:\n",
    "    corp_debt[i] = data(i,'d')\n",
    "\n",
    "#corp_debt.index = pd.to_datetime(corp_debt.index)\n",
    "\n",
    "corp_debt_y = corp_debt.groupby(pd.Grouper(freq='1YE')).mean()\n",
    "corp_debt_std = corp_debt.rolling(21).std()\n",
    "\n",
    "#Corporate Debt Yields\n",
    "corp = corp_debt\n",
    "corp.columns = ['1-3yrs','3-5yrs','5-7yrs','7-10yrs','10-15yrs','15+ yrs','High Yield Index','US Corp Index']\n",
    "corp_curve = corp.drop(columns=['High Yield Index','US Corp Index'])\n",
    "corp_curve = corp_curve.loc[corp_curve.index.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CPI indicators\n",
    "indicators = list(['CPIUFDSL','CUSR0000SAF11','CUSR0000SEFV','CPIENGSL','CUSR0000SETB01','CUSR0000SEHE','CUSR0000SEHF','CUSR0000SEHF01','CUSR0000SACL1E','CUSR0000SAD','CUSR0000SAN','CUSR0000SASLE','CUSR0000SAH1','CUSR0000SAM2','CUSR0000SAS4','CPIAUCSL'])\n",
    "\n",
    "cpi = pd.DataFrame()\n",
    "for i in indicators:\n",
    "    cpi[i] = data(i,'m')\n",
    "\n",
    "cpi_yoy = (cpi / cpi.shift(12))-1\n",
    "\n",
    "p = pd.DataFrame()\n",
    "\n",
    "for i in prices:\n",
    "    y = data(i,'m')\n",
    "    p[i] = y.value\n",
    "\n",
    "p['cpi_growth_yoy'] = p.CPIAUCSL / p.CPIAUCSL.shift(12) - 1\n",
    "p['pce_growth_yoy'] = p.PCE / p.PCE.shift(12) - 1\n",
    "p['ppi_growth_yoy'] = p.PPIACO / p.PPIACO.shift(12) - 1\n",
    "\n",
    "#CPI\n",
    "consumer = cpi_yoy*100\n",
    "consumer.columns = [\"All items\",\"Food\",\"Food at home\",\"Food away from home(1)\",\"Energy\",\"Gasoline\",\"Fuel Oil\",\"Energy services\",\"Electricity\",\"Commodities\",\"Durable Goods\",\"Non-Durable Goods\",\"Service\",\"Shelter\",\"Medical\",\"Transportation\"]\n",
    "\n",
    "#Prices Index\n",
    "prices = p*100\n",
    "#prices.index = pd.to_datetime(prices.index)\n",
    "prices = prices.drop(columns=['CPIAUCSL','PCE','PPIACO'])\n",
    "prices.columns = ['CPI YoY','PCE YoY','PPI YoY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Tables Formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary\n",
    "#S&P 500\n",
    "sp = pd.DataFrame()\n",
    "sp['close'] = daily('^GSPC')\n",
    "sp['100ma'] = sp.close.rolling(100).mean()\n",
    "sp['200ma'] = sp.close.rolling(200).mean()\n",
    "sp['30mstd'] = sp.close.pct_change().rolling(30).std()*100\n",
    "sp['60mstd'] = sp.close.pct_change().rolling(60).std()*100\n",
    "sp['100mstd'] = sp.close.pct_change().rolling(100).std()*100\n",
    "sp['200mstd'] = sp.close.pct_change().rolling(200).std()*100\n",
    "sp['zscore 100ma'] = (sp.close - sp.close.mean())/sp.close.std()\n",
    "sp['daily'] = sp.close.pct_change()*100\n",
    "sp['mom'] = ((sp.close/sp.close.shift(30))-1)*100\n",
    "sp['yoy'] = ((sp.close/sp.close.shift(365))-1)*100\n",
    "sp['ytd'] = (sp.groupby(sp.index.year)['close'].transform(lambda x: x / x.iloc[0] - 1))*100\n",
    "sp['vix'] = daily('^VIX')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Summary\n",
    "summary_rows = ['S&P 500','S&P 500 Daily Growth','30d Moving Sigma','VIX','1mo Bill','10yr Treasury']\n",
    "summary = pd.DataFrame(index=summary_rows)\n",
    "from datetime import date\n",
    "\n",
    "today_date = date.today()\n",
    "today_date = today_date.strftime(\"%Y-%m-%d\")\n",
    "today_date\n",
    "\n",
    "\n",
    "summary[today_date] = [\n",
    "    sp.close.tail(1).values[0],\n",
    "    sp.daily.tail(1).values[0],\n",
    "    sp['30mstd'].tail(1).values[0],\n",
    "    sp.vix.tail(1).values[0],\n",
    "    yield_curve['1mo'],\n",
    "    yield_curve['1yr']\n",
    "]\n",
    "\n",
    "summary['30 Mean'] = [sp.close.tail(30).mean(),\n",
    "                   sp.daily.tail(20).mean(),\n",
    "                   sp['30mstd'].tail(1).values[0],\n",
    "                   sp.vix.tail(30).mean(),\n",
    "                   yields['1mo'].tail(30).mean(),\n",
    "                   yields['10yr'].tail(30).mean()\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#S&P Plots\n",
    "sp_plot = sp.tail(30)\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "\n",
    "# Create a figure and axes for the grid\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 10))\n",
    "\n",
    "# Plot 1: S&P Plots\n",
    "axes[0, 0].plot(sp_plot.index,sp_plot.close,'k-o')\n",
    "axes[0, 0].plot(sp_plot.index,sp_plot['100ma'],'r')\n",
    "axes[0, 0].plot(sp_plot.index,sp_plot['200ma'],'b')\n",
    "axes[0, 0].set_title('Benchmark')\n",
    "axes[0, 0].legend(['S&P 500','100ma','200ma'])\n",
    "\n",
    "# Plot 2: S&P 500 Moving Volatility\n",
    "axes[0, 1].plot(sp_plot.index,sp_plot['30mstd'])\n",
    "axes[0, 1].plot(sp_plot.index,sp_plot['100mstd'])\n",
    "axes[0, 1].plot(sp_plot.index,sp_plot['200mstd'])\n",
    "axes[0, 1].set_title('S&P 500 Moving Volatility')\n",
    "axes[0, 1].legend(['30m','100m','200m'])\n",
    "\n",
    "# Plot 3: S&P 500 Performance\n",
    "axes[0, 2].plot(sp_plot.index,sp_plot['daily'])\n",
    "axes[0, 2].plot(sp_plot.index,sp_plot['mom'])\n",
    "axes[0, 2].plot(sp_plot.index,sp_plot['yoy'])\n",
    "axes[0, 2].plot(sp_plot.index,sp_plot['ytd'])\n",
    "axes[0, 2].set_title('S&P 500 Performance')\n",
    "axes[0, 2].legend(['Daily','MoM','YoY','YTD'])\n",
    "\n",
    "# Plot 4: S&P 500 VIX\n",
    "axes[1, 0].plot(sp_plot.vix,'k-o')\n",
    "axes[1, 0].set_title('S&P 500 VIX')\n",
    "\n",
    "# Plot 5: Options Pricing and Volume\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.tight_layout()\n",
    "\n",
    "op_data = options_data(\"SPY\",1)\n",
    "options_dates = list(op_data[0].options)\n",
    "options_dates = pd.to_datetime(options_dates)\n",
    "for i, date in enumerate(options_dates):\n",
    "    if date.month == 12:\n",
    "        last_december_index = i\n",
    "\n",
    "op_data = options_data(\"SPY\",last_december_index)\n",
    "\n",
    "option_chain = op_data[1]\n",
    "axes[1, 1].plot(option_chain.calls.strike, option_chain.calls.volume,'go',label='Calls Volume')\n",
    "axes[1, 1].plot(option_chain.puts.strike, option_chain.puts.volume,'mo',label='Puts Volume')\n",
    "axes[1, 1].axvline(x= op_data[2].values  , color='k', linestyle='--', linewidth=1)\n",
    "axes[1, 1].legend(loc='upper right')\n",
    "axes[1, 1].set_xlabel('Strike Price')\n",
    "axes[1, 1].set_ylabel('$')\n",
    "axes[1, 1].set_title('Options Volume')\n",
    "axes[1, 1].set_ylabel('Volume')\n",
    "\n",
    "# Plot 6: Options Pricing and Volume - 2\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.tight_layout()\n",
    "\n",
    "# Assuming op_data is the list of dates you provided\n",
    "op_data = options_data(\"SPY\",last_december_index)\n",
    "\n",
    "option_chain = op_data[1]\n",
    "axes[1, 2].plot(option_chain.calls.strike, option_chain.calls.lastPrice, 'ro', label='Calls Price')\n",
    "axes[1, 2].plot(option_chain.puts.strike, option_chain.puts.lastPrice, 'bo', label='Puts Price')\n",
    "axes[1, 2].axvline(x= op_data[2].values  , color='k', linestyle='--', linewidth=1)\n",
    "axes[1, 2].legend(loc='upper right')\n",
    "axes[1, 2].set_xlabel('Strike Price')\n",
    "axes[1, 2].set_ylabel('$')\n",
    "\n",
    "ax2 = axes[1, 2].twinx()\n",
    "ax2.plot(option_chain.calls.strike, option_chain.calls.impliedVolatility,'go',label='Calls IV')\n",
    "ax2.plot(option_chain.puts.strike, option_chain.puts.impliedVolatility,'mo',label='Puts IV')\n",
    "ax2.legend(loc='lower right')\n",
    "ax2.set_ylabel('Volume')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('spy_plots.png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.tight_layout()\n",
    "plt.title('Equity Sectors Trailling Correlation')\n",
    "plt.bar(sectors_names,sectors_data.groupby(pd.Grouper(freq='1ME')).mean().tail(12).corr()['^GSPC']*100,color='none', edgecolor='blue', linewidth=2)\n",
    "plt.bar(sectors_names,sectors_data.groupby(pd.Grouper(freq='1ME')).mean().tail(6).corr()['^GSPC']*100,color='none', edgecolor='red', linewidth=2)\n",
    "plt.bar(sectors_names,sectors_data.groupby(pd.Grouper(freq='1ME')).mean().tail(3).corr()['^GSPC']*100,color='none', edgecolor='green', linewidth=2)\n",
    "plt.grid(True)\n",
    "plt.legend(['12 Months','6 Months','3 Months'])\n",
    "plt.savefig(\"sectors correlation.png\")\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "\n",
    "# Plot the bars\n",
    "plt.bar(sectors_names, ((sectors_data.iloc[len(sectors_data)-1]/sectors_data.iloc[len(sectors_data)-2])-1)*100 , color='none', edgecolor='blue', linewidth=2, label='1-day Growth')\n",
    "plt.bar(sectors_names, ((sectors_data.iloc[len(sectors_data)-1]/sectors_data.iloc[len(sectors_data)-8])-1)*100 , color='none', edgecolor='red', linewidth=2, label='7-day Growth')\n",
    "plt.bar(sectors_names, ((sectors_data.iloc[len(sectors_data)-1]/sectors_data.iloc[len(sectors_data)-31])-1)*100 , color='none', edgecolor='green', linewidth=2, label='30-day Growth')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Sectors')\n",
    "plt.ylabel('Growth')\n",
    "plt.title('Equity Sectors Perfomance')\n",
    "plt.legend()  # Add a legend to distinguish between different time periods\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('equity sectors perfomance.png')\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.tight_layout()\n",
    "\n",
    "tickers = ['XLY', 'XLP', 'XLE', 'XLF', 'XLV', 'XLI', 'XLB', 'XLRE', 'XLK', 'XLC', 'XLU']\n",
    "num_plots = len(tickers)\n",
    "sectors_names = ['Consumer Discretionary', 'Consumer Staples', 'Energy', 'Financials', 'Health Care', 'Industrials', 'Materials', 'Real Estate', 'Technology', 'Communication Services', 'Utilities']\n",
    "\n",
    "num_rows = 3\n",
    "num_cols = 4\n",
    "\n",
    "# Create subplots in a 3x4 grid\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(15, 10))\n",
    "\n",
    "# Flatten the axes array to iterate over it in a single loop\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, ticker, sector_name in zip(axes, tickers, sectors_names):\n",
    "    option_chain = options_data(ticker, 1)[1]\n",
    "    ax.plot(option_chain.calls.strike, option_chain.calls.impliedVolatility, 'ro', label=f'{ticker} Calls')\n",
    "    ax.plot(option_chain.puts.strike, option_chain.puts.impliedVolatility, 'bo', label=f'{ticker} Puts')\n",
    "    ax.axvline(x= options_data(ticker,1)[2].values  , color='k', linestyle='--', linewidth=1)\n",
    "    ax.legend(loc='upper right')\n",
    "    ax.set_xlabel('Strike Price')\n",
    "    ax.set_ylabel('Implied Volatility')\n",
    "    ax.set_title(f'Options Volatility - {sector_name}')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig('equity sectors options volatility.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yields Plots\n",
    "yields_plot =yields.tail(10)\n",
    "\n",
    "\n",
    "# Create a figure and axes for the grid\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Plot 1: Yield Curve\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "axes[0].plot(yields_plot.columns, yields.iloc[len(yields.index)-6], marker='o', linestyle='-',color='black')\n",
    "axes[0].plot(yields_plot.columns, yields.iloc[len(yields.index)-1], marker='o', linestyle='-',color='blue')\n",
    "axes[0].plot(yields_plot.columns, yields.iloc[len(yields.index)-13], marker='o', linestyle='-',color='red')\n",
    "axes[0].plot(yields_plot.columns, yields.iloc[len(yields.index)-29], marker='o', linestyle='-',color='green')\n",
    "axes[0].legend([yields.iloc[len(yields.index)-6].name,\n",
    "                yields.iloc[len(yields.index)-1].name,\n",
    "                yields.iloc[len(yields.index)-13].name,\n",
    "                yields.iloc[len(yields.index)-29].name])\n",
    "axes[0].set_title('Yield Curve')\n",
    "axes[0].set_xlabel('Maturity')\n",
    "axes[0].set_ylabel('Interest Rate')\n",
    "\n",
    "# Plot 2: Yield Historical\n",
    "sns.set_style(\"whitegrid\")\n",
    "axes[1].plot(yields_plot.index,yields_plot['1mo'],'-o')\n",
    "axes[1].plot(yields_plot.index,yields_plot['1yr'],'-o')\n",
    "axes[1].plot(yields_plot.index,yields_plot['10yr'],'-o')\n",
    "axes[1].plot(yields_plot.index,yields_plot['30yr'],'-o')\n",
    "axes[1].set_title('Yield Historical')\n",
    "axes[1].legend(['1mo','1yr','10yr','30yr'])\n",
    "axes[1].set_xlabel('Date')\n",
    "axes[1].set_ylabel('Interest Rate')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('treasury curve.png')\n",
    "\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.tight_layout()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(yields_plot, annot=True, fmt=\".2f\", cmap=\"inferno\")\n",
    "plt.title('Yield Curve Trailling')\n",
    "plt.ylabel('Date')\n",
    "plt.savefig('yield curve trailling heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CPI Plots\n",
    "consumer_plot = consumer.tail(12)\n",
    "prices_plot = prices.tail(12)\n",
    "\n",
    "# Create a figure and axes for the grid\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# Plot 1: CPI Categories Heatmap\n",
    "sns.set_style(\"whitegrid\")\n",
    "#sns.heatmap(consumer_plot, annot=True, fmt=\".2f\", cmap=\"inferno\", ax=axes[0])\n",
    "sns.heatmap(consumer_plot.T, annot=False, cmap=\"coolwarm\", linewidths=.5, cbar_kws={'label': '% YoY Change'},ax=axes[0])\n",
    "axes[0].set_title('CPI Categories')\n",
    "axes[0].set_ylabel('Date')\n",
    "\n",
    "# Plot 2: Price Indexes YoY% Change\n",
    "sns.set_style(\"whitegrid\")\n",
    "axes[1].plot(prices_plot)\n",
    "axes[1].set_title('Price Indexes YoY% Change')\n",
    "axes[1].legend(['CPI','PCE','PPI'])\n",
    "\n",
    "\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('cpi plots.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Use the latest 12 data points for the plots\n",
    "consumer_plot = consumer.tail(12)\n",
    "num_categories = len(consumer_plot.columns)\n",
    "\n",
    "# Create subplots based on the number of categories (e.g., 4 rows and 4 columns)\n",
    "fig, axes = plt.subplots(4, 4, figsize=(20, 16))  # Adjust as needed\n",
    "fig.suptitle('YoY Change in Price Index by Category', fontsize=16)\n",
    "\n",
    "# Flatten axes to easily iterate over them\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot each category individually\n",
    "for i, col in enumerate(consumer_plot.columns):\n",
    "    axes[i].plot(consumer_plot.index, consumer_plot[col])\n",
    "    axes[i].set_title(col)\n",
    "    axes[i].set_xticks([])  # Optionally remove x-ticks for clarity\n",
    "    axes[i].set_ylabel('% Change')\n",
    "\n",
    "# Remove any empty subplots (in case the number of categories doesn't perfectly fit)\n",
    "for j in range(i + 1, len(axes)):\n",
    "    fig.delaxes(axes[j])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('yoy_change_by_category.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Use the latest 12 data points for the plots\n",
    "consumer_plot = consumer.tail(12)\n",
    "prices_plot = prices.tail(12)\n",
    "\n",
    "# Create a figure and axes for a 2x2 grid, with a more moderate size and DPI\n",
    "fig, axes = plt.subplots(2, 2, figsize=(24, 16), dpi=100)  # Reduced figsize and DPI for better browser display\n",
    "\n",
    "### Plot 1: CPI Categories Heatmap ###\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.heatmap(consumer_plot.T, annot=False, cmap=\"coolwarm\", linewidths=.5, cbar_kws={'label': '% YoY Change'}, ax=axes[0, 0])\n",
    "axes[0, 0].set_title('CPI Categories', fontsize=16)\n",
    "axes[0, 0].set_ylabel('Date', fontsize=14)\n",
    "\n",
    "### Plot 2: Price Indexes YoY% Change ###\n",
    "sns.set_style(\"whitegrid\")\n",
    "axes[0, 1].plot(prices_plot)\n",
    "axes[0, 1].set_title('Price Indexes YoY% Change', fontsize=16)\n",
    "axes[0, 1].legend(['CPI', 'PCE', 'PPI'], fontsize=12)\n",
    "axes[0, 1].tick_params(axis='x', labelsize=12)\n",
    "axes[0, 1].tick_params(axis='y', labelsize=12)\n",
    "\n",
    "### Plot 3: Individual YoY Change in Price Index by Category ###\n",
    "num_categories = len(consumer_plot.columns)\n",
    "axes_3 = axes[1, 0]\n",
    "\n",
    "# Define a vibrant color palette using 'husl' (it generates bright, vibrant colors)\n",
    "colors = sns.color_palette(\"husl\", num_categories)\n",
    "\n",
    "# Plot all categories on a single axis with vibrant colors\n",
    "for i, column in enumerate(consumer_plot.columns):\n",
    "    axes_3.plot(consumer_plot.index, consumer_plot[column], label=column, color=colors[i], alpha=0.8)\n",
    "axes_3.set_title('YoY Change in Price Index for CPI Categories', fontsize=16)\n",
    "axes_3.set_ylabel('% YoY Change', fontsize=14)\n",
    "axes_3.set_xlabel('Date', fontsize=14)\n",
    "axes_3.grid(True)\n",
    "axes_3.legend(loc='lower center', bbox_to_anchor=(0.5, -0.25), ncol=4, fontsize=12, fancybox=True, shadow=True)\n",
    "axes_3.set_xticklabels(consumer_plot.index, rotation=45, fontsize=12)\n",
    "\n",
    "### Plot 4: Grouped Bar Chart of YoY Change in Price Index Across Categories ###\n",
    "consumer_plot.plot(kind='bar', ax=axes[1, 1], width=0.8)\n",
    "axes[1, 1].set_title('YoY Change in Price Index Across Categories', fontsize=16)\n",
    "axes[1, 1].set_ylabel('% YoY Change', fontsize=14)\n",
    "axes[1, 1].set_xlabel('Date', fontsize=14)\n",
    "axes[1, 1].legend(loc='lower center', bbox_to_anchor=(0.5, -0.25), ncol=4, fontsize=12, fancybox=True, shadow=True)\n",
    "axes[1, 1].tick_params(axis='x', labelsize=12)\n",
    "axes[1, 1].tick_params(axis='y', labelsize=12)\n",
    "\n",
    "### Adjust layout and increase space between plots ###\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.4)\n",
    "\n",
    "# Save the figure with a reasonable resolution\n",
    "plt.savefig('combined_cpi_plots_2x2.png', dpi=150)  # Reduced DPI for faster rendering in HTML\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Labor Market Plots\n",
    "labor_market_plot = labor_market.tail(24)\n",
    "\n",
    "# Create a figure and axes for the grid\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "\n",
    "# Plot 1: Employment Indicators\n",
    "axes[0, 0].plot(labor_market_plot.index, labor_market_plot['Nonfarm Change'], color='black', label='Payems Change')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Payems Change')\n",
    "axes[0, 0].legend(['NonFarm Payroll'])\n",
    "\n",
    "# Create a secondary y-axis\n",
    "ax2 = axes[0, 0].twinx()\n",
    "# Plot on the secondary y-axis\n",
    "ax2.plot(labor_market_plot.index, labor_market_plot['Unemployment Rate'], color='green', label='Unemployment Rate')\n",
    "ax2.set_ylabel('Unemployment Rate')\n",
    "ax2.legend(['Unemployment Rate'])\n",
    "axes[0, 0].set_title('Employment Indicators')\n",
    "\n",
    "# Plot 2: Unemployment Rate\n",
    "axes[0, 1].grid(True)\n",
    "axes[0, 1].plot(labor_market_plot['Unemployment Rate'],'-ok')\n",
    "axes[0, 1].plot(labor_market['Unemployment Rate'].rolling(3).mean().tail(len(labor_market_plot)),'o')\n",
    "axes[0, 1].plot(labor_market['Unemployment Rate'].rolling(6).mean().tail(len(labor_market_plot)),'o')\n",
    "axes[0, 1].plot(labor_market['Unemployment Rate'].rolling(12).mean().tail(len(labor_market_plot)),'o')\n",
    "axes[0, 1].set_title('Unemployment Rate')\n",
    "axes[0, 1].set_ylabel('%')\n",
    "axes[0, 1].set_xlabel('Date')\n",
    "axes[0, 1].legend(['Current Rate','3M MA','6M MA','12M MA'])\n",
    "\n",
    "# Plot 3: Labor Forces\n",
    "axes[1, 0].plot(labor_market_plot.index, labor_market_plot['Labor Demand'],'-o')\n",
    "axes[1, 0].plot(labor_market_plot.index, labor_market_plot['Labor Supply'],'-o')\n",
    "axes[1, 0].set_ylabel('Thousands of Persons')\n",
    "ax2 = axes[1, 0].twinx()\n",
    "ax2.plot(labor_market_plot.index, labor_market_plot['Labor Difference'],'k-o')\n",
    "ax2.set_ylabel('Labor Difference')\n",
    "axes[1, 0].set_title('Labor Forces')\n",
    "axes[1, 0].legend(['Labor Demand','Labor Supply'])\n",
    "\n",
    "# Plot 4: Weekly Earnings\n",
    "axes[1, 1].plot(labor_market_plot.index, labor_market_plot['Average Weekly Hours'],'b-o')\n",
    "axes[1, 1].plot(labor_market_plot.index, labor_market_plot['Average Hourly Earnings'],'g-o')\n",
    "axes[1, 1].legend(['Average Weekly Hours','Average Hourly Earnings'])\n",
    "ax2 = axes[1, 1].twinx()\n",
    "ax2.plot(labor_market_plot.index, labor_market_plot['AWH YoY%'],'-o')\n",
    "ax2.plot(labor_market_plot.index, labor_market_plot['AHE YoY%'],'-o')\n",
    "axes[1, 1].legend(['Average Weekly Hours YoY%','Average Hourly Earnings YoY%'])\n",
    "axes[1, 1].set_title('Weekly Earnings')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('labor indicators.png')\n",
    "\n",
    "# Show the plot\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting data and plots into a PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "today =datetime.now().strftime(\"%Y-%m-%d @ %H:%M\")\n",
    "date_time = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "context = {'date_time':today,\n",
    "           'sp500_value':  \"${:,.2f}\".format(summary[date_time].iloc[0])\n",
    "           ,'sp500_daily': \"{:,.2f}%\".format(summary[date_time].iloc[1])\n",
    "           ,'sp500_30d_std': \"{:,.2f}\".format(summary[date_time].iloc[2])\n",
    "           ,'vix': \"{:,.2f}\".format(summary[date_time].iloc[3])\n",
    "           ,'tbill': \"{:,.2f}\".format(summary[date_time].iloc[4])\n",
    "           ,'tbond': \"{:,.2f}\".format(summary[date_time].iloc[5])\n",
    "           ,'yields_table' : yields_plot.tail(5).to_html()\n",
    "           }\n",
    "\n",
    "template_loader = jinja2.FileSystemLoader('./')\n",
    "template_env = jinja2.Environment(loader=template_loader)\n",
    "\n",
    "template = template_env.get_template(\"Econ Report Template.html\")\n",
    "output_text = template.render(context)\n",
    "\n",
    "file_path = \"Econ Report.html\"\n",
    "with open(file_path, \"w\",encoding=\"utf-8\") as file:\n",
    "    file.write(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yields.index = pd.to_datetime(yields.index)\n",
    "yields_annual = yields.groupby(pd.Grouper(freq='1YE')).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "prod.index = pd.to_datetime(prod.index)\n",
    "prod_annual = prod.groupby(pd.Grouper(freq='1YE')).sum()\n",
    "#prod_annual.index = pd.to_datetime(prod_annual.index)\n",
    "\n",
    "\n",
    "prod_annual['GDP YoY'] = prod_annual['GDP'].pct_change()\n",
    "prod_annual['RGDP YoY'] = prod_annual['GDPC1'].pct_change()\n",
    "prod_annual['GDI YoY'] = prod_annual['GDI'].pct_change()\n",
    "prod_annual['RGDI YoY'] = prod_annual['A261RX1Q020SBEA'].pct_change()\n",
    "\n",
    "prod['GDP QoQ'] = prod['GDP'].pct_change()\n",
    "prod['RGDP QoQ'] = prod['GDPC1'].pct_change()\n",
    "prod['GDI QoQ'] = prod['GDI'].pct_change()\n",
    "prod['RGDI QoQ'] = prod['A261RX1Q020SBEA'].pct_change()\n",
    "\n",
    "prod['GDP Growth Annualized'] = (1 + prod['GDP QoQ'])**4 - 1\n",
    "prod['RGDP Growth Annualized'] = (1 + prod['RGDP QoQ'])**4 - 1\n",
    "prod['GDI Growth Annualized'] = (1 + prod['GDI QoQ'])**4 - 1\n",
    "prod['RGDI Growth Annualized'] = (1 + prod['RGDI QoQ'])**4 - 1\n",
    "\n",
    "prod.replace('inf',0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_annual = pd.DataFrame(sp.close.groupby(pd.Grouper(freq='1YE')).last())\n",
    "sp_annual['yoy'] = sp_annual.close.pct_change()\n",
    "sp_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Excel File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.ExcelWriter('Econ Data Link.xlsx', engine='xlsxwriter') as writer:\n",
    "    yields.to_excel(writer, sheet_name='Daily Yields', index=True)\n",
    "    yields_annual.to_excel(writer, sheet_name='Annualized Yields', index=True)\n",
    "    prod.to_excel(writer,sheet_name='National Product',index=True)\n",
    "    prod_annual.to_excel(writer,sheet_name='Annualized National Product',index=True)\n",
    "    sp.to_excel(writer, sheet_name='S&P 500',index=True)\n",
    "    sp_annual.to_excel(writer, sheet_name='Annualized S&P 500',index=True)\n",
    "    df.to_excel(writer, sheet_name='Meta Data',index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connection parameters - you'll need to update these with your actual database details\n",
    "server ='localhost'\n",
    "port = '1433'\n",
    "database = 'master'\n",
    "username = 'sa'\n",
    "password = 'yourStrong(!)Password'\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "conn_str = f'mssql+pyodbc://{username}:{password}@{server}:{port}/{database}?driver=ODBC+Driver+17+for+SQL+Server'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.exc import SQLAlchemyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(conn_str)\n",
    "connection = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Insert Labor Market data\n",
    "lm.to_sql('LaborMarket', engine, if_exists='append')\n",
    "\n",
    "# Insert Treasury Yields data\n",
    "yields.to_sql('TreasuryYields', engine, if_exists='append')\n",
    "\n",
    "# Insert Corporate Debt data\n",
    "corp.to_sql('CorporateDebt', engine, if_exists='append')\n",
    "\n",
    "# Insert CPI Components data\n",
    "consumer.to_sql('CPIComponents', engine, if_exists='append')\n",
    "\n",
    "# Insert Price Indices data\n",
    "prices.to_sql('PriceIndices', engine, if_exists='append')\n",
    "\n",
    "# Insert S&P 500 data\n",
    "sp.to_sql('SP500', engine, if_exists='append')\n",
    "\n",
    "# Insert Market Sectors data\n",
    "sectors_data.to_sql('MarketSectors', engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
